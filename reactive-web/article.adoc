= Going Reactive with WebFlux

== I/O, I/O, It's Off to Work We Go...

Reactive programming is an approach to writing software that embraces asynchronous IO. Asynchronous I/O is a small idea that portends big changes for software. The idea is simple: alleviate inefficient resource utilization by reclaiming resources that would otherwise be idle as they waited for I/O activity. Asynchronous IO inverts the normal design of IO processing: the clients are notified of new data instead of asking for it; this frees the client to do other things while waiting for new notifications. Let's look at an example that compares and contrasts asynchronous IO to synchronous IO.

Let's build a simple program that reads data from a source (a `java.io.File` reference, specifically). First up, an implementation that uses a trusty 'ol `java.io.InputStream` implementation:

.Read data from a file _synchronously_
====
[source,java,indent=0]
----
include::./src/main/java/com/example/io/Synchronous.java[]
----
<1> source the file using a regular `java.io.File`
<2> _pull_ the results out of the source one line at a time..
<3> I've written this code to accept a `Consumer<BytesPayload>` that gets called when there's new data
====

Pretty straightforward, eh? Run this and you'll see in the log output, on the left hand side of each line, that all activity is happening on a single thread.

We're _pulling_ bytes out of a source of data (in this case, a `java.io.InputStream` subclass, `java.io.FileInputStream`). What's wrong with this example? Well, probably nothing! In this case we're using an `InputStream` that's pointing to data on the local file system. If the file is there, and the hard drive is working, then this code will work as we expect.

What if, instead of reading data from a `File`, we read data from a network socket, and used a different implementation of an `InputStream`? Nothing to worry about! Well, nothing to worry about if the network is infinitely fast, at least. And if the network link between this node and another never fails. If those things are true, then there's certainly nothing to worry about! This code will work just fine..

What happens if the network is slow, or down? In this case, it'd mean that the time it takes for the `in.read(...)` operation to return would be prolonged. Indeed, it may never return! This is a problem if we're trying to do something else with the thread on which we're reading data. Sure, we can spin up another thread and read from that one instead. We could keep this up to a point, but eventually we'll run into a limit where adding threads doesn't support our goal of scaling. We won't have true concurrency beyond the number of cores on our machine. We're stuck! We can't handle more I/O, reads in this case, without adding threads, and our ability to scale up with more threads is, ultimately, limited.

In that example, the bulk of the work is in the reading - there's not much else going on anywhere. We are __I/O bound_. Let's see how an asynchronous solution can help us alleviate the monopolization of our threads.

.Read data from a file _asynchronously_
====
[source,java,indent=0]
----
include::./src/main/java/com/example/io/Asynchronous.java[]
----
<1> this time, we adapt the `java.io.File` into a Java NIO `java.nio.file.Path`
<2> when we create the `Channel`, we specify, among other things, a `java.util.concurrent.ExecutorService`, that will be used to invoke our `CompletionHandler` when there's data available.
<3> start reading, passing in a reference to a `CompletionHandler<Integer, ByteBuffer>` (`this`).
<4> in the callback, we read the bytes out of  a `ByteBuffer` into a `byte[]` holder.
<5> Just as in the `Synchronous` example, the `byte[]` data is passed to a consumer.
====

First thing's first: this code's _waaaay_ more complicated! There's a ton of things going on here and it can seem overwhelming, but indulge me, for a moment... This code  reads data from a Java NIO `Channel` and processes that data, asynchronously, on a separate thread in a callback handler. The thread on which the read was started isn't monopolized. We return virtually instantly after we call `.read(..)`, and when there is finally data available, our callback is invoked, and on a different thread. If there is latency between `.read()` calls, then we can move on and do other things with our thread. The duration of the asynchronous read, from the first byte to the last, is at best as short as the duration of the synchronous read. It's likely a tiny bit longer. But, for that complexity, we can be more efficient with our threads. We can handle more work, multiplexing I/O across a finite thread pool.

I work for a cloud computing company. We'd love it if you solved your scale-out problems by buying more application instances! I say that, tongue in cheek, to highlight the ultimate benefit of reactive code: we can handle more requests, and do more work, using asynchronous I/O on the same hardware.


// is this enough? most of us dont focus at the level of input and output. certainly not! how do i bridge the last section (IO) to the need for a computational metaphor? spend a few paragraphs explaining the need for a computtion metaphor that lends itself to the approach we choose for IO.

== The Missing Metaphor

There is always the risk that too many notifications will overwhelm a client. A client must be able to push back, rejecting work it can't handle. This is a fundamental aspect of flow control in distributed systems. In reactive programming, the ability of the client to signal how much work it can manage is called _backpressure_. Many projects - like Vert.x, Akka Streams, and RxJava - support reactive programming. The Spring team has a project called http://projectreactor.io[Reactor]. There's common ground across these different approaches extracted into a de-facto standard, http://www.reactive-streams.org[the Reactive Streams initiative]. The Reactive Streams initiative defines four types:

The `Publisher<T>` is a producer of values that may eventually arrive. A `Publisher<T>` produces values of type `T`.

.the Reactive Streams `Publisher<T>`.
====
[source,java,indent=0]
----
package org.reactivestreams;

public interface Publisher<T> {

    void subscribe(Subscriber<? super T> s);
}
----
====

The `Subscriber` subscribes to a `Publisher<T>`, receiving notifications on any new values of type `T`.

.the Reactive Streams `Subscriber<T>`.
====
[source,java,indent=0]
----
package org.reactivestreams;

public interface Subscriber<T> {

    public void onSubscribe(Subscription s);

    public void onNext(T t);

    public void onError(Throwable t);

    public void onComplete();
}
----
====

When a `Subscriber<T>` subscribes to a `Publisher<T>`, it results in a `Subscription<T>` being given to the subscriber. The `Subscription` is arguably the most important part of the application. Think about what's happening here: you're inverting the traditional interaction with your source of data. Instead of, say, reading `byte[]` data into a buffer one scoop of data at a time, you're being given the data when it's available.

.The Reactive Streams `Subscription<T>`.
====
[source,java,indent=0]
----
package org.reactivestreams;

public interface Subscription {

    public void request(long n);

    public void cancel();
}
----
====

A `Publisher<T>` that is also a `Subscriber<T>` is called a `Processor<T>`.

.The Reactive Streams `Processor<T>`.
====
[source,java,indent=0]
----
package org.reactivestreams;

public interface Processor<T, R> extends Subscriber<T>, Publisher<R> {
}
----
====

The specification is not meant to be a prescription for the implementations,   instead defining types for interoperability. The Reactive Streams types eventually found their way into Java 9 as one to one semantically equivalent interfaces in the `java.util.concurrent.Flow` class.


== Reactor
The Reactive Streams types are not enough; you'll need higher order implementations to support operators like filtering and transformation. Pivotal's Reactor project is a good choice here; it builds on top of the Reactive Streams specification. It provides two specializations of the `Publisher<T>`. The first, `Flux<T>`, is a Publisher that produces zero or more values. It's unbounded. The second, `Mono<T>`, is a `Publisher<T>` that produces zero or one value. They're both publishers and you can treat them that way, but they go much further than the  Reactive Streams specification. They both provide operators, ways to  process a stream of values. Reactor types compose nicely - the output of one thing can be the input to another.

== Reactive Spring
As useful as project Reactor is, it's only a foundation. Our applications need to talk to data sources. They need to produce and consume HTTP, SSE and WebSocket endpoints. They support authentication and authorization. Spring provides these things. If Reactor gives us the missing metaphor, Spring helps us all speak the same language.

Spring Framework 5.0 was released in September 2017. It builds on Reactor and the Reactive Streams specification. It includes a new reactive runtime and component model called https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web-reactive.html#webflux[Spring WebFlux]. Spring WebFlux does not depend on or require the Servlet APIs to work. It ships with adapters that allow it to work on top of a Servlet-engine, if need be, but it's not required. It also provides a Netty-based web server. Spring Framework 5, which works with a baseline of Java 8 and Java EE 7 -  is the foundation for changes in much of the Spring ecosystem.


